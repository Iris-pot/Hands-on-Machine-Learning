[toc]

# 聚类

## K-Means

思想：给定由n个样本组成的集合，将样本集合划分成k个子集，构成k个类，将n个样本划分到k个类中。保证每个样本到其所属类的类中心的距离最近。

K-Means算法是典型的**基于距离**的**非层次聚类算法**，在最小化误差函数的基础上将数据划分为**预定的类数K**，采用**距离作为相似性的评价指标**，即认为两个对象的距离越近，其相似度就越大。

1.算法过程
1）从N个样本数据中**随机选取K个对象作为初始的聚类中心。**
2）分别**计算每个样本到各个聚类中心的距离，**将对象**分配**到距离最近的聚类中。
3）所有对象分配完成后，**重新计算K个聚类的中心，即新的类的中心。**
4）与前一次计算得到的K个聚类中心比较，如果**聚类中心发生变化**，转过程2），否则转过程5）。
5）当**质心不发生变化时停止**并输出聚类结果。



缺点：

- 需要人工确定k值
- 只能收敛到局部最优，效果受到初始值很大影响
- 易受到早点的影响
- 每个样本点只能划分到单一的类中

优点：时间复杂度接近于线性，因此适用于大的数据集

调优：

- 归一化和离群点处理
- k值的选择-经验法则，手肘法/gap statistic（随机样本与实际样本的损失之差，取得最大值时的k值）
- 核函数（非线性映射，将输入空间映射到特征空间中，变得线性可分）

改进模型：

- k-Means++（一次性随机选择k个簇中心，变成依次选择k个；步骤：先随机确定第一个簇中心，距离它越远的样本点被选中为簇中心的概率越大）
- ISODATA（自适应迭代选择k的值；如果类别中样本数目过少，就删除类，如果样本数目过多，就分裂成两个类；参数：参考k，最小距离，最大方差，最少样本数）



## 层次聚类

分类：聚合聚类；分裂聚类

### 聚合聚类：

原理：将初始的n个类中最近的两个类合并，重复直到满足停止条件

步骤：

- 计算n个样本点间的距离
- 将n个样本点分为n个类
- 将距离最小的两个类合并
- 计算新的类和原有类之间的距离，合并，直到类的个数为阈值

## 聚类的评估：

- 估计聚类趋势：检查数据分布中是否存在**非随机**的簇结构
- 判定数据簇数：计算手肘法，gap statistic统计量--确定k值
- 测定聚类质量：轮廓系数（簇间距离远，簇内距离近）；均方根标准误差；R2；改进的Hubert gamma系数；不一致指数

# 关联规则

提取关联规则的最大困难在于当存在很多商品时，可能的商品的组合的数目会达到一种令人望而却步的程度。因而各种关联规则分析的算法从不同方面入手，以减小可能的搜索空间的大小以及减小扫描数据的次数。

Apriori算法是最经典的挖掘频繁项集的算法，第一次实现了在大数据集上可行的关联规则提取，其核心思想是**通过连接产生候选项与其支持度，然后通过剪枝生成频繁项集。**







# 时间序列



![image-20200611145213726](C:\Users\zmy\AppData\Roaming\Typora\typora-user-images\image-20200611145213726.png)







